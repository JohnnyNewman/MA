{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T007\n"
     ]
    }
   ],
   "source": [
    "df_result, df_surface = save_collected_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_excel(\"save/T007/df_result.xlsx\")\n",
    "df_surface.to_excel(\"save/T007/df_surface.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_surface, open(\"save/T007/df_surface.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = \"T007\"\n",
    "dv_list = pickle.load(open(os.path.join(\"CollectedData\", dir1, \"dv_list.p\"), \"rb\"))\n",
    "AOA_mat = pickle.load(open(os.path.join(\"CollectedData\", dir1, \"AOA_mat.p\"), \"rb\"))\n",
    "Ma_mat = pickle.load(open(os.path.join(\"CollectedData\", dir1, \"Ma_mat.p\"), \"rb\"))\n",
    "\n",
    "dv_mat = np.asarray(dv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = df_result[\"DIR\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = [\"x\", \"y\"]\n",
    "dir_names = dir_list\n",
    "\n",
    "N = len(dir_names)\n",
    "M = len(input_columns)\n",
    "\n",
    "X = np.zeros((N, M, 192))\n",
    "Y = np.zeros((N, 4, 192))\n",
    "\n",
    "for i, dir in enumerate(dir_names):\n",
    "    print(dir)\n",
    "    df_surface_flow = df_surface[df_surface[\"DIR\"] == dir]\n",
    "    X[i,0,:] = df_surface_flow[\"x\"]\n",
    "    X[i,1,:] = df_surface_flow[\"y\"]\n",
    "    Y[i,0,:] = df_surface_flow[\"Pressure_Coefficient\"]\n",
    "    Y[i,1,1:-1] = 0.1*(Y[i,0,2:] - Y[i,0,:-2] ) / np.sqrt( (X[i,0,2:] - X[i,0,:-2])**2 + (X[i,1,2:] - X[i,1,:-2])**2 )\n",
    "    \n",
    "    #Y[i,1,:] = df_surface_flow[\"Surface_Sensitivity\"]\n",
    "    Y[i,2,:] = df_surface_flow[\"Skin_Friction_Coefficient_x\"]\n",
    "    Y[i,3,:] = df_surface_flow[\"Skin_Friction_Coefficient_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[:,1,:] = np.clip(Y[:,1,:], -3, 3) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_result[\"rms_rho\"] <= -6\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(df_result[\"rms_nu\"], df_result[\"c_D\"], \"o\", label=\"nu\")\n",
    "plt.plot(df_result[\"rms_rho\"], df_result[\"c_D\"], \"o\")\n",
    "plt.vlines([-6], 0.01, 0.1, ls=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_result[\"rms_rho\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[a]\n",
    "Y = Y[a]\n",
    "#dv_mat = dv_mat[a]\n",
    "\n",
    "dv_mat = dv_mat[:a.shape[0]][a]\n",
    "AOA_mat = AOA_mat[:a.shape[0]][a]\n",
    "Ma_mat = Ma_mat[:a.shape[0]][a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack((Ma_mat.reshape(-1, 1), AOA_mat.reshape(-1, 1), dv_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 3, figsize=(16,40))\n",
    "\n",
    "#plt.gca().invert_yaxis()\n",
    "\n",
    "for k, ax in enumerate(axes.flat):\n",
    "    i = int(k / 3) + 100\n",
    "    j = k % 3\n",
    "    #ax.plot(X[i,:,0], Y[i,:,0], \".\")\n",
    "    #ax.plot(X[i,:,0], Y[i,:,j], \".\")\n",
    "    if j == 0:\n",
    "        ax.plot(X[i,0,:], X[i,1,:], \"-\")\n",
    "        ax.set_ylim((-0.2, 0.2))\n",
    "        ax.grid(True, \"both\")\n",
    "        #ax.set_subtitle(\"GEO\")\n",
    "    elif j == 1:\n",
    "        ax.scatter(X[i,0,:], Y[i,0,:],c=np.linspace(0, 1, 192))\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "    elif j == 2:\n",
    "        ax.scatter(X[i,0,:], Y[i,1,:],c=np.linspace(0, 1, 192))\n",
    "    ax.set_title(dir_names[i][-7:] + f\" {Ma_mat[i]:.3f} {AOA_mat[i]:.1f}\")\n",
    "    #print(-np.sum(0.5*(Y[i,1:,0]*dx + Y[i,:-1,0]*dx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ma = torch.from_numpy(Ma_mat).ast\n",
    "AOA = torch.from_numpy(AOA_mat)\n",
    "dvs = torch.from_numpy(dv_mat)\n",
    "X_pt = torch.from_numpy(X)\n",
    "Y_pt = torch.from_numpy(Y)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(Ma, AOA, dvs, X_pt, Y_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ma.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dataset, open(\"save/T007/full_dataset.p\", \"wb\"))\n",
    "pickle.dump(train_dataset, open(\"save/T007/train_dataset.p\", \"wb\"))\n",
    "pickle.dump(test_dataset, open(\"save/T007/test_dataset.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pickle.load(open(\"save/T007/full_dataset.p\", \"rb\"))\n",
    "train_dataset = pickle.load(open(\"save/T007/train_dataset.p\", \"rb\"))\n",
    "test_dataset = pickle.load(open(\"save/T007/test_dataset.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirfoilModel(LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = 128\n",
    "        #self.hparams.batch_size = 64\n",
    "        \n",
    "        c1 = 8\n",
    "        c2 = 8\n",
    "        k2 = 8\n",
    "        c3 = 8 \n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, width, height)\n",
    "        self.layer_0 = nn.Conv1d(in_channels=2,out_channels=c1,kernel_size=3,stride=1, padding=1)\n",
    "\n",
    "        self.layer_11 = nn.Conv1d(in_channels=c1,out_channels=c2,kernel_size=3,stride=1, padding=1)\n",
    "        self.layer_12 = nn.Conv1d(in_channels=c1,out_channels=c2,kernel_size=3,stride=1, padding=1)\n",
    "        self.layer_13 = nn.Conv1d(in_channels=c1,out_channels=c2,kernel_size=3,stride=1, padding=1)\n",
    "        self.layer_14 = nn.Conv1d(in_channels=c1,out_channels=c2,kernel_size=3,stride=1, padding=1)\n",
    "        self.relu_11 = nn.ReLU()\n",
    "        self.relu_12 = nn.ReLU()\n",
    "        self.relu_13 = nn.ReLU()\n",
    "        self.relu_14 = nn.ReLU()\n",
    "\n",
    "        self.layer_2 = nn.Conv1d(in_channels=8*4,out_channels=c3,kernel_size=5,stride=2, padding=1)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        \n",
    "        self.layer_3 = torch.nn.Linear(287, 8)\n",
    "        \n",
    "        \n",
    "        self.layer_5 = torch.nn.Linear(66, 32)\n",
    "        \n",
    "        self.layer_6 = torch.nn.Linear(32, 32)\n",
    "        self.relu_6 = nn.ReLU()\n",
    "        self.layer_7 = torch.nn.Linear(32, 32)\n",
    "        self.relu_7 = nn.ReLU()\n",
    "        self.layer_8 = torch.nn.Linear(32, 32)\n",
    "        self.relu_8 = nn.ReLU()\n",
    "        self.layer_9 = torch.nn.Linear(32, 32)\n",
    "        self.relu_9 = nn.ReLU()\n",
    "        self.layer_10 = torch.nn.Linear(32, 64)\n",
    "        self.relu_10 = nn.ReLU()\n",
    "        \n",
    "        c4 = 32\n",
    "        c5 = 16\n",
    "        c6 = 8\n",
    "        self.deconv_11 = nn.ConvTranspose1d(in_channels=64, out_channels=c4, kernel_size=7, stride=3, dilation=3)\n",
    "        self.deconv_12 = nn.ConvTranspose1d(in_channels=c4, out_channels=c5, kernel_size=7, stride=3, dilation=3)\n",
    "        self.relu_12 = nn.ReLU()\n",
    "        self.deconv_13 = nn.ConvTranspose1d(in_channels=c5, out_channels=c6, kernel_size=7, stride=3, dilation=3)\n",
    "        self.relu_13 = nn.ReLU()\n",
    "        self.deconv_14 = nn.ConvTranspose1d(in_channels=c6, out_channels=4, kernel_size=7, stride=1, dilation=1)\n",
    "        \n",
    "        \n",
    "        self.loss_crit = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, Ma, AOA):\n",
    "        #batch_size, channels, width, height = x.size()\n",
    "        \n",
    "        ### Encoder\n",
    "        \n",
    "        xxx = torch.cat((x, x, x), dim=2)\n",
    "        x_0 = self.layer_0(xxx)\n",
    "\n",
    "        x_11 = self.relu_11(self.layer_11(x_0))\n",
    "        x_12 = self.relu_12(self.layer_12(x_0))\n",
    "        x_13 = self.relu_13(self.layer_13(x_0))\n",
    "        x_14 = self.relu_14(self.layer_14(x_0))\n",
    "\n",
    "        x_1 = torch.cat((x_11, x_12, x_13, x_14), dim=1)\n",
    "        \n",
    "        x_2 = self.relu_2(self.layer_2(x_1))\n",
    "        x_3 = self.layer_3(x_2).view(-1, 1, 64)\n",
    "        \n",
    "        #print(x_3.shape, AOA.shape, Ma.shape)\n",
    "        \n",
    "        r = torch.randn_like(x_3)\n",
    "        x_3 = x_3 + r\n",
    "        \n",
    "        ### Decoder\n",
    "        \n",
    "        x_4 = torch.cat((x_3, AOA.view(-1, 1, 1), Ma.view(-1, 1, 1)), dim=2)\n",
    "        \n",
    "        x_5 = self.layer_5(x_4)\n",
    "        \n",
    "        x_6 = self.relu_6(self.layer_6(x_5))\n",
    "        x_7 = self.relu_7(self.layer_7(x_6))\n",
    "        \n",
    "        x_8 = self.relu_8(self.layer_8(x_5+x_7))\n",
    "        x_9 = self.relu_9(self.layer_9(x_8))\n",
    "        \n",
    "        x_10 = self.relu_10(self.layer_10(x_9+x_7))\n",
    "        \n",
    "        x_11 = self.deconv_11(x_10.view(-1, 64, 1))\n",
    "        x_12 = self.relu_12(self.deconv_12(x_11))\n",
    "        x_13 = self.relu_13(self.deconv_13(x_12))\n",
    "        x_14 = self.deconv_14(x_13)\n",
    "        \n",
    "        y = x_14\n",
    "        \n",
    "        d = y.shape[2] - x.shape[2]\n",
    "        d0 = int(d/2)\n",
    "        #print(d)\n",
    "        \n",
    "        out_mask = torch.ones(y.shape[2], dtype=torch.long)\n",
    "        out_mask[:d0] = 0\n",
    "        out_mask[-d0+d:] = 0\n",
    "        \n",
    "        #print(d,d0)\n",
    "        \n",
    "        return y[:,:,d0:d0-d]\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        ma, aoa, dv, x, y = batch\n",
    "        x_hat = self(x, ma, aoa)\n",
    "        loss = F.mse_loss(x_hat, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        ma, aoa, dv, x, y = batch\n",
    "        x_hat = self(x, ma, aoa)\n",
    "        loss = F.mse_loss(x_hat, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        #print(\"get dataloader \", self.batch_size)\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, num_workers=0, shuffle=True, pin_memory=True)    \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(test_dataset, batch_size=len(test_dataset), num_workers=0, pin_memory=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 192])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma, aoa, dv, x, y = train_dataset[0:3]\n",
    "\n",
    "model = AirfoilModel()\n",
    "model = model.double()\n",
    "\n",
    "y = model(x, ma, aoa)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AirfoilModel(\n",
       "  (layer_0): Conv1d(2, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (layer_11): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (layer_12): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (layer_13): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (layer_14): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (relu_11): ReLU()\n",
       "  (relu_12): ReLU()\n",
       "  (relu_13): ReLU()\n",
       "  (relu_14): ReLU()\n",
       "  (layer_2): Conv1d(32, 8, kernel_size=(5,), stride=(2,), padding=(1,))\n",
       "  (relu_2): ReLU()\n",
       "  (layer_3): Linear(in_features=287, out_features=8, bias=True)\n",
       "  (layer_5): Linear(in_features=66, out_features=32, bias=True)\n",
       "  (layer_6): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (relu_6): ReLU()\n",
       "  (layer_7): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (relu_7): ReLU()\n",
       "  (layer_8): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (relu_8): ReLU()\n",
       "  (layer_9): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (relu_9): ReLU()\n",
       "  (layer_10): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (relu_10): ReLU()\n",
       "  (deconv_11): ConvTranspose1d(64, 32, kernel_size=(7,), stride=(3,), dilation=(3,))\n",
       "  (deconv_12): ConvTranspose1d(32, 16, kernel_size=(7,), stride=(3,), dilation=(3,))\n",
       "  (deconv_13): ConvTranspose1d(16, 8, kernel_size=(7,), stride=(3,), dilation=(3,))\n",
       "  (deconv_14): ConvTranspose1d(8, 4, kernel_size=(7,), stride=(1,))\n",
       "  (loss_crit): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 192])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "   | Name      | Type            | Params\n",
      "-----------------------------------------------\n",
      "0  | layer_0   | Conv1d          | 56    \n",
      "1  | layer_11  | Conv1d          | 200   \n",
      "2  | layer_12  | Conv1d          | 200   \n",
      "3  | layer_13  | Conv1d          | 200   \n",
      "4  | layer_14  | Conv1d          | 200   \n",
      "5  | relu_11   | ReLU            | 0     \n",
      "6  | relu_12   | ReLU            | 0     \n",
      "7  | relu_13   | ReLU            | 0     \n",
      "8  | relu_14   | ReLU            | 0     \n",
      "9  | layer_2   | Conv1d          | 1 K   \n",
      "10 | relu_2    | ReLU            | 0     \n",
      "11 | layer_3   | Linear          | 2 K   \n",
      "12 | layer_5   | Linear          | 2 K   \n",
      "13 | layer_6   | Linear          | 1 K   \n",
      "14 | relu_6    | ReLU            | 0     \n",
      "15 | layer_7   | Linear          | 1 K   \n",
      "16 | relu_7    | ReLU            | 0     \n",
      "17 | layer_8   | Linear          | 1 K   \n",
      "18 | relu_8    | ReLU            | 0     \n",
      "19 | layer_9   | Linear          | 1 K   \n",
      "20 | relu_9    | ReLU            | 0     \n",
      "21 | layer_10  | Linear          | 2 K   \n",
      "22 | relu_10   | ReLU            | 0     \n",
      "23 | deconv_11 | ConvTranspose1d | 14 K  \n",
      "24 | deconv_12 | ConvTranspose1d | 3 K   \n",
      "25 | deconv_13 | ConvTranspose1d | 904   \n",
      "26 | deconv_14 | ConvTranspose1d | 228   \n",
      "27 | loss_crit | MSELoss         | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.39it/s, loss=4.397, v_num=38]\n",
      "Epoch 3: : 13it [00:02,  6.31it/s, loss=4.397, v_num=38]                                                               \n",
      "Epoch 7: 100%|███████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.47it/s, loss=2.334, v_num=38]\n",
      "Epoch 7: : 13it [00:02,  6.41it/s, loss=2.334, v_num=38]                                                               \n",
      "Epoch 11: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.44it/s, loss=1.785, v_num=38]\n",
      "Epoch 11: : 13it [00:02,  6.40it/s, loss=1.785, v_num=38]                                                              \n",
      "Epoch 15: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.38it/s, loss=1.558, v_num=38]\n",
      "Epoch 15: : 13it [00:02,  6.35it/s, loss=1.558, v_num=38]                                                              \n",
      "Epoch 19: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.13it/s, loss=1.485, v_num=38]\n",
      "Epoch 19: : 13it [00:02,  6.14it/s, loss=1.485, v_num=38]                                                              \n",
      "Epoch 23: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.48it/s, loss=1.449, v_num=38]\n",
      "Epoch 23: : 13it [00:02,  6.42it/s, loss=1.449, v_num=38]                                                              \n",
      "Epoch 27: 100%|██████████████████████████████████████████████████| 12/12 [00:02<00:00,  4.96it/s, loss=1.443, v_num=38]\n",
      "Epoch 27: : 13it [00:02,  4.96it/s, loss=1.443, v_num=38]                                                              \n",
      "Epoch 31: 100%|██████████████████████████████████████████████████| 12/12 [00:02<00:00,  4.87it/s, loss=1.426, v_num=38]\n",
      "Epoch 31: : 13it [00:02,  4.61it/s, loss=1.426, v_num=38]                                                              \n",
      "Epoch 35: 100%|██████████████████████████████████████████████████| 12/12 [00:02<00:00,  4.02it/s, loss=1.434, v_num=38]\n",
      "Epoch 35: : 13it [00:03,  3.99it/s, loss=1.434, v_num=38]                                                              \n",
      "Epoch 39: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.13it/s, loss=1.383, v_num=38]\n",
      "Epoch 39: : 13it [00:02,  6.16it/s, loss=1.383, v_num=38]                                                              \n",
      "Epoch 43: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.38it/s, loss=1.389, v_num=38]\n",
      "Epoch 43: : 13it [00:02,  6.38it/s, loss=1.389, v_num=38]                                                              \n",
      "Epoch 47: 100%|██████████████████████████████████████████████████| 12/12 [00:02<00:00,  5.80it/s, loss=1.417, v_num=38]\n",
      "Epoch 47: : 13it [00:02,  5.79it/s, loss=1.417, v_num=38]                                                              \n",
      "Epoch 51: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.36it/s, loss=1.374, v_num=38]\n",
      "Epoch 51: : 13it [00:02,  6.29it/s, loss=1.374, v_num=38]                                                              \n",
      "Epoch 55: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.38it/s, loss=1.369, v_num=38]\n",
      "Epoch 55: : 13it [00:02,  6.31it/s, loss=1.369, v_num=38]                                                              \n",
      "Epoch 59: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.41it/s, loss=1.393, v_num=38]\n",
      "Epoch 59: : 13it [00:02,  6.36it/s, loss=1.393, v_num=38]                                                              \n",
      "Epoch 63: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.42it/s, loss=1.370, v_num=38]\n",
      "Epoch 63: : 13it [00:02,  6.44it/s, loss=1.370, v_num=38]                                                              \n",
      "Epoch 67: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.37it/s, loss=1.363, v_num=38]\n",
      "Epoch 67: : 13it [00:02,  6.37it/s, loss=1.363, v_num=38]                                                              \n",
      "Epoch 71: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.33it/s, loss=1.428, v_num=38]\n",
      "Epoch 71: : 13it [00:02,  6.18it/s, loss=1.428, v_num=38]                                                              \n",
      "Epoch 75: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.39it/s, loss=1.364, v_num=38]\n",
      "Epoch 75: : 13it [00:02,  6.38it/s, loss=1.364, v_num=38]                                                              \n",
      "Epoch 79: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.40it/s, loss=1.344, v_num=38]\n",
      "Epoch 79: : 13it [00:02,  6.40it/s, loss=1.344, v_num=38]                                                              \n",
      "Epoch 83: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.34it/s, loss=1.379, v_num=38]\n",
      "Epoch 83: : 13it [00:02,  6.29it/s, loss=1.379, v_num=38]                                                              \n",
      "Epoch 87: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.31it/s, loss=1.358, v_num=38]\n",
      "Epoch 87: : 13it [00:02,  6.24it/s, loss=1.358, v_num=38]                                                              \n",
      "Epoch 91: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.03it/s, loss=1.366, v_num=38]\n",
      "Epoch 91: : 13it [00:02,  6.06it/s, loss=1.366, v_num=38]                                                              \n",
      "Epoch 95: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.30it/s, loss=1.376, v_num=38]\n",
      "Epoch 95: : 13it [00:02,  6.28it/s, loss=1.376, v_num=38]                                                              \n",
      "Epoch 99: 100%|██████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.30it/s, loss=1.359, v_num=38]\n",
      "Epoch 99: : 13it [00:02,  6.31it/s, loss=1.359, v_num=38]                                                              \n",
      "Epoch 102:  50%|█████████████████████████                         | 6/12 [00:00<00:00,  6.10it/s, loss=1.320, v_num=38]"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(gpus=1, weights_summary='full', precision=16, check_val_every_n_epoch=4) #, auto_scale_batch_size=None\n",
    "#train_loader = DataLoader(train_dataset, batch_size=1468, shuffle=True, pin_memory=True)\n",
    "#val_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "#trainer.fit(model, train_loader)\n",
    "#trainer.tune(model)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batch_size, model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__()\n",
    "        \n",
    "        self.hidden_size = 16\n",
    "        self.bidirectional = True\n",
    "        \n",
    "        c1, c2, c3 = 32, 64, 32\n",
    "        c4, c5, c6 = 32, 64, 64\n",
    "                \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=2,out_channels=c1,kernel_size=15,stride=1, padding=7),\n",
    "            nn.PReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3),\n",
    "            nn.Conv1d(in_channels=c1,out_channels=c2,kernel_size=15,stride=1, padding=7),\n",
    "            nn.PReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=c2,out_channels=c3,kernel_size=15,stride=1, padding=7),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(32,64),\n",
    "            #nn.PReLU(),\n",
    "            #nn.Linear(64,32),\n",
    "            #nn.PReLU(),\n",
    "            nn.Conv1d(in_channels=c3,out_channels=1,kernel_size=1,stride=1),\n",
    "        )\n",
    "    \n",
    "        self.decoder = nn.Sequential(\n",
    "            #nn.MaxUnpool1d(kernel_size=3),\n",
    "            nn.Linear(64,64),\n",
    "            nn.ConvTranspose1d(in_channels=1, out_channels=c4, kernel_size=7,stride=2),\n",
    "            nn.PReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=c4, out_channels=c5, kernel_size=7,stride=2),\n",
    "            nn.PReLU(),\n",
    "            #nn.MaxPool1d(kernel_size=2),\n",
    "            nn.ConvTranspose1d(in_channels=c5, out_channels=c6, kernel_size=7,stride=2),\n",
    "            nn.PReLU(),\n",
    "            #nn.MaxPool1d(kernel_size=2),\n",
    "            nn.ConvTranspose1d(in_channels=c6, out_channels=4, kernel_size=7,stride=2),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_stacked = torch.cat((x, x, x), dim=2)\n",
    "        \n",
    "        z = self.encoder(x)\n",
    "        r = torch.randn_like(z)\n",
    "        \n",
    "        y = self.decoder(z + r)\n",
    "        \n",
    "        d = y.shape[2] - x.shape[2]\n",
    "        d0 = int(d/2)\n",
    "        #print(d)\n",
    "        \n",
    "        out_mask = torch.ones(y.shape[2], dtype=torch.long)\n",
    "        out_mask[:d0] = 0\n",
    "        out_mask[-d0+d:] = 0\n",
    "        \n",
    "        #print(d,d0)\n",
    "        \n",
    "        return y[:,:,d0:d0-d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
